{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU_simple_bench.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fenz/notebook_workspace/blob/master/TPU_simple_bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "znQzDEofkmTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install watermark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DfDgYbuQkYfG",
        "colab_type": "code",
        "outputId": "61c9a0fc-6698-4575-f574-b02e6a4e09e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark -p tensorflow,numpy -m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow 1.12.0\n",
            "numpy 1.14.6\n",
            "\n",
            "compiler   : GCC 8.2.0\n",
            "system     : Linux\n",
            "release    : 4.14.65+\n",
            "machine    : x86_64\n",
            "processor  : x86_64\n",
            "CPU cores  : 2\n",
            "interpreter: 64bit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iiKZQmfpki8Y",
        "colab_type": "code",
        "outputId": "7b995b58-f1dc-4b79-a99c-686d732508f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "def calc(n):\n",
        "  img = tf.random_normal((128, 100, 100, 3))\n",
        "  def body(_):\n",
        "    result = tf.layers.conv2d(img, 32, 7)\n",
        "    result = tf.reduce_sum(result)\n",
        "    return result\n",
        "\n",
        "  return tf.contrib.tpu.repeat(n[0], body, [0.0])\n",
        "\n",
        "\n",
        "session = tf.Session('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "try:\n",
        "  print('Initializing TPU...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "\n",
        "  for i in [1, 10, 100, 500]:\n",
        "    tpu_ops = tf.contrib.tpu.batch_parallel(calc, [[i] * 8], num_shards=8)\n",
        "    print('Warming up...')\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tpu_ops)\n",
        "    print('Profiling')\n",
        "    start = time.time()\n",
        "    session.run(tpu_ops)\n",
        "    end = time.time()\n",
        "    elapsed = end - start\n",
        "    print(i, elapsed)\n",
        "finally:\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing TPU...\n",
            "Warming up...\n",
            "Profiling\n",
            "1 0.009667634963989258\n",
            "Warming up...\n",
            "Profiling\n",
            "10 0.03323030471801758\n",
            "Warming up...\n",
            "Profiling\n",
            "100 0.2860987186431885\n",
            "Warming up...\n",
            "Profiling\n",
            "500 1.4136693477630615\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}